{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2f82cc24efc6283e5a98cadb78fc1a465e44c143",
        "collapsed": true,
        "id": "zXE5nCqkDg2S"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "_uuid": "da0236e4b36ce514c1fec3fd72f236d1fa259131",
        "id": "1FNsnfdiDg2U"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries, fill the import name libraries below\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "import pandas as pd\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Import keras libraries that you need\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "import math\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA6ISWySDg2V"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "_uuid": "b288a8e2caf6196daec9cd2bc4ca78fe50345845",
        "id": "9Kgd5jTCDg2V"
      },
      "outputs": [],
      "source": [
        "# Some functions to help out with this code\n",
        "def prediction_plot(test,predicted):\n",
        "    plt.plot(test,predicted, color='k')\n",
        "    #fill the function to predict\n",
        "    plt.show\n",
        "\n",
        "def rmse_eval(test,predicted):\n",
        "    #fill the function for evaluation model\n",
        "    return np.sqrt(np.mean(np.square(test - predicted)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "_uuid": "4cf10cf27420eb383b93b15c0895139ea96c0ed3",
        "id": "eDQk0TpuDg2W"
      },
      "outputs": [],
      "source": [
        "# Import Dataset\n",
        "dataset = pd.read_csv(\"/content/GOOGL_2006-01-01_to_2018-01-01.csv\") #import dataset based on your directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for min-max normalization of stock\n",
        "def normalize_data(dataset):\n",
        "    min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
        "    dataset['open'] = min_max_scaler.fit_transform(dataset.open.values.reshape(-1,1))\n",
        "    dataset['high'] = min_max_scaler.fit_transform(dataset.high.values.reshape(-1,1))\n",
        "    dataset['low'] = min_max_scaler.fit_transform(dataset.low.values.reshape(-1,1))\n",
        "    dataset['close'] = min_max_scaler.fit_transform(dataset['close'].values.reshape(-1,1))\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "HRo6B4eSF_5Y"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe with only the 'Close column\n",
        "data = dataset.filter(['Close'])\n",
        "# Convert the dataframe to a numpy array\n",
        "dataset = data.values\n",
        "# Get the number of rows to train the model on\n",
        "training_data_len = int(np.ceil( len(dataset) * .8 ))\n",
        "\n",
        "\n",
        "training_data_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RE5V_0kGYgA",
        "outputId": "d6995f0d-62a1-4e24-c0cf-b614d7af56a4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2416"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "_uuid": "fb4c9db6d8a5bcf20ffad41747cfa5b6215ba220",
        "id": "OHnmj0rfDg2W"
      },
      "outputs": [],
      "source": [
        "# Checking for missing values, choose for data training and set in kind of year\n",
        "#a : until year training\n",
        "#b : year for testing\n",
        "training_set = dataset.iloc[:,0].values\n",
        "test_set = dataset.iloc[:,1].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiw8mupjDg2W"
      },
      "source": [
        "### Write your insight in EDA here\n",
        "Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "_uuid": "bf5a9463d58e73852d2b70be9611e8cf1f4166fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiHYGjJ9Dg2W",
        "outputId": "a715c1e9-0658-4992-d4fe-875f13e851ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "#Checking for stock's market company with line plot\n",
        "#Write your code below\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "_uuid": "bcc9c36165fc07d258bd5ea87874d2da17fa4a4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29evHwNEDg2X",
        "outputId": "5c8ac51f-2631-4ecf-a337-d822e225c694"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09305195],\n",
              "       [0.09829122],\n",
              "       [0.10143897],\n",
              "       ...,\n",
              "       [0.97397097],\n",
              "       [0.96952648],\n",
              "       [0.96685978]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Scaling with minmaxscaller for data train\n",
        "# Scale the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(dataset)\n",
        "\n",
        "scaled_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "UBIU33yODg2X"
      },
      "outputs": [],
      "source": [
        "#checking shape of data train\n",
        "# Create the training data set\n",
        "# Create the scaled training data set\n",
        "train_data = scaled_data[0:int(training_data_len), :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "_uuid": "fccfb866a2b4c702e0b2742f7c0289512d713d1b",
        "id": "UI_DB19NDg2X"
      },
      "outputs": [],
      "source": [
        "# 将过去60天的closing price作为输入，预测第六十一天的closing price\n",
        "\n",
        "# Create the training data set\n",
        "# Create the scaled training data set\n",
        "train_data = scaled_data[0:int(training_data_len), :]\n",
        "# Split the data into x_train and y_train data sets\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(60, len(train_data)):\n",
        "    x_train.append(train_data[i-30:i, 0])\n",
        "    y_train.append(train_data[i, 0])\n",
        "    if i<= 31:\n",
        "        print(x_train,len(x_train))\n",
        "        print(y_train,len(y_train))\n",
        "        print()\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "_uuid": "637f699d3c4bde4b783de56ed4dd70a1bf59760d",
        "id": "Fr_tdq9vDg2X"
      },
      "outputs": [],
      "source": [
        "# Reshaping X_train before modelling\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "# x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDTKisnVDg2X"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "_uuid": "df20eb7e8062dae0a3aff2182aa440faddd0017d",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd_MPdCdDg2Y",
        "outputId": "081cb342-f096-46d6-8caa-ff6e50f49f6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.engine.sequential.Sequential object at 0x7bf2ca2dd420>\n",
            "2356/2356 [==============================] - 57s 23ms/step - loss: 0.0029\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7bf2c9fb0f70>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Sequential Modelling\n",
        "model = Sequential()\n",
        "# First LSTM layer with Dropout regularisation\n",
        "model.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "# Second LSTM layer\n",
        "model.add(Dense(2))\n",
        "# Third LSTM layer, fill the code below\n",
        "model.add(Dense(3))\n",
        "# Fourth LSTM layer, fill the code below\n",
        "model.add(Dense(4))\n",
        "# The output layer\n",
        "print(model)\n",
        "# Compiling\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "# Train fitting for the model\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "_uuid": "326fa85615622feb484cc4c848edeec6f7133913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLJlh2OYDg2Y",
        "outputId": "93ac1860-3427-45dc-d853-ac8ca902c6f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 1s 21ms/step\n"
          ]
        }
      ],
      "source": [
        "# Create the testing data set\n",
        "# Create a new array containing scaled values from index 1543 to 2002\n",
        "test_data = scaled_data[training_data_len - 30: , :]\n",
        "# Create the data sets x_test and y_test\n",
        "x_test = []\n",
        "y_test = dataset[training_data_len:, :]\n",
        "\n",
        "for i in range(30, len(test_data)):\n",
        "    x_test.append(test_data[i-30:i, 0])\n",
        "\n",
        "# print(test_data[31-30:31, 0])\n",
        "# print(x_test.shape[1], 1)\n",
        "\n",
        "# Convert the data to a numpy array\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "\n",
        "# Reshape the data\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
        "# print(x_test[0:2])\n",
        "\n",
        "# Get the models predicted price values\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGHTg6dcDg2Y"
      },
      "outputs": [],
      "source": [
        "#checking data test shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cO--bO4Dg2Y"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "_uuid": "435b8024814939ac4fbd372baa0cd8cfc78f80bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzghhf77Dg2Y",
        "outputId": "92d97989-06e9-471e-a62c-e9dcc04d987f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 19ms/step\n"
          ]
        }
      ],
      "source": [
        "# Preparing X_test and predicting the prices of the stock's that you choose\n",
        "x_test = []\n",
        "for i in range(60, 100):\n",
        "    x_test.append(train_data[i-60:i,0])\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1], 1))\n",
        "#Predicting stocks price\n",
        "pred_stock_price = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "_uuid": "f6f6db0b6e1f17ac63c06ce49856873d98ba5f00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRzW5gJwDg2Y",
        "outputId": "17cde903-6d3a-4f13-aa55-9f514b4137df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62.71251419056543"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# Evaluating our model with RMSE function above\n",
        "rmse_eval = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
        "rmse_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a4cf704ab3cd091f63b7b9a1b9224a49f0913171",
        "id": "A2EzKbb6Dg2Z"
      },
      "source": [
        "### Write your Insight and advice here :)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrFXTeaSDg2Z"
      },
      "source": [
        "Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}